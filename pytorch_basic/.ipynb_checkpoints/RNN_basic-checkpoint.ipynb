{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6447317-50ae-422d-9cd9-dcdd0c53d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f6278677-07dd-4214-b547-ab259bc84249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ 0 ============\n",
      "input_size: torch.Size([2, 4])\n",
      "torch.float32\n",
      "torch.float32\n",
      "output_size: torch.Size([2, 2])\n",
      "tensor([[-0.8323,  0.3388],\n",
      "        [ 0.3986,  0.6711]], grad_fn=<TanhBackward0>)\n",
      "============ 1 ============\n",
      "input_size: torch.Size([2, 4])\n",
      "torch.float32\n",
      "torch.float32\n",
      "output_size: torch.Size([2, 2])\n",
      "tensor([[-0.9278, -0.5077],\n",
      "        [-0.9987, -0.9079]], grad_fn=<TanhBackward0>)\n",
      "============ 2 ============\n",
      "input_size: torch.Size([2, 4])\n",
      "torch.float32\n",
      "torch.float32\n",
      "output_size: torch.Size([2, 2])\n",
      "tensor([[-0.5757,  0.0725],\n",
      "        [-0.1552,  0.6591]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#How to use RNNCell\n",
    "batch_size=2\n",
    "seq_len=3\n",
    "input_size=4\n",
    "hidden_size=2\n",
    "cell=torch.nn.RNNCell(input_size=input_size,hidden_size=hidden_size)\n",
    "dataset=torch.randn(seq_len,batch_size,input_size)\n",
    "hidden=torch.zeros(batch_size,hidden_size)\n",
    "for idx,input in enumerate(dataset,0):\n",
    "    print(\"=\"*12,idx,\"=\"*12)\n",
    "    print(\"input_size:\",input.shape)\n",
    "    print(input.dtype)\n",
    "    print(hidden.dtype)\n",
    "    hidden=cell(input,hidden)\n",
    "    print(\"output_size:\",hidden.shape)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "299869b5-e942-4908-b0a5-6952b21e83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output_size: torch.Size([3, 1, 2])\n",
      "Output: tensor([[[0.7498, 0.1833]],\n",
      "\n",
      "        [[0.9132, 0.8118]],\n",
      "\n",
      "        [[0.9391, 0.4266]]], grad_fn=<StackBackward0>)\n",
      "hidden_size: torch.Size([2, 1, 2])\n",
      "hidden: tensor([[[-0.4206,  0.6046]],\n",
      "\n",
      "        [[ 0.9391,  0.4266]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#How to use RNN\n",
    "input_size=4\n",
    "seq_len=3\n",
    "hidden_size=2\n",
    "num_layers=2\n",
    "batch_size=1\n",
    "cell=torch.nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "inputs=torch.randn(seq_len,batch_size,input_size)\n",
    "hidden=torch.zeros(num_layers,batch_size,hidden_size)\n",
    "out,hidden=cell(inputs,hidden)\n",
    "#hidden.shape=(num_layers,batch_size,hidden_size)\n",
    "#out.shape=(seq_len,batch_size,hidden_size)\n",
    "print(\"Output_size:\",out.shape)\n",
    "print(\"Output:\",out)\n",
    "print(\"hidden_size:\",hidden.shape)\n",
    "print(\"hidden:\",hidden)\n",
    "#在torch.nn.RNN()中有个设置batch_first=True只需要将inputs中seq_len和batch_size互换位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c6c5bb3a-2909-4311-a712-5b49f65d384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 4])\n",
      "tensor([[[0., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1.]]])\n",
      "torch.Size([5, 1])\n",
      "tensor([[3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [2]])\n"
     ]
    }
   ],
   "source": [
    "#One-hot vectors 独热编码\n",
    "#将hello转化成ohlol\n",
    "#导入数据\n",
    "batch_size=1\n",
    "input_size=4\n",
    "hidden_size=4\n",
    "num_layers=1\n",
    "seq_len=5\n",
    "idx2char=['e','h','l','o']\n",
    "x_data=[1,0,2,2,3]\n",
    "y_data=[3,1,2,3,2]\n",
    "one_hot_lookup=[[1,0,0,0],\n",
    "                [0,1,0,0],\n",
    "                [0,0,1,0],\n",
    "                [0,0,0,1]]\n",
    "one_hot_x=[one_hot_lookup[x] for x in x_data]\n",
    "inputs=torch.tensor(one_hot_x).view(-1,batch_size,input_size).to(torch.float32) #-1处是seq_len,注意inputs从列表转化过来的数据类型是int64，需要转化成float32才能被神经网路接受\n",
    "labels=torch.LongTensor(y_data).view(-1,1) #标签的形状是(seq_len*1)\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cba79123-b5fe-4dd2-907f-d538ad55013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用RNNCell实现一下\n",
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,batch_size):\n",
    "        super(Net1,self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.batch_size=batch_size\n",
    "        self.rnncell=torch.nn.RNNCell(input_size=input_size,hidden_size=hidden_size)\n",
    "    def forward(self,input,hidden):\n",
    "        hidden=self.rnncell(input,hidden)\n",
    "        return hidden\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size,self.hidden_size)\n",
    "model1=Net1(input_size,hidden_size,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d8c54903-5568-440a-b255-96c2bc2dd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失和优化函数\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model1.parameters(),lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "290502b2-2187-44b6-98be-7f09bc73ddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string: lloll, Epoch [1/15] loss is:6.0964\n",
      "Predicted string: ohooo, Epoch [2/15] loss is:4.4539\n",
      "Predicted string: ohlol, Epoch [3/15] loss is:4.0322\n",
      "Predicted string: ohlol, Epoch [4/15] loss is:4.0755\n",
      "Predicted string: ohlol, Epoch [5/15] loss is:4.0117\n",
      "Predicted string: ohlol, Epoch [6/15] loss is:3.8690\n",
      "Predicted string: ooloo, Epoch [7/15] loss is:3.6564\n",
      "Predicted string: ooloo, Epoch [8/15] loss is:3.5979\n",
      "Predicted string: ooloo, Epoch [9/15] loss is:3.3437\n",
      "Predicted string: ohlol, Epoch [10/15] loss is:2.4880\n",
      "Predicted string: ohlol, Epoch [11/15] loss is:1.7879\n",
      "Predicted string: ohlol, Epoch [12/15] loss is:1.7156\n",
      "Predicted string: ohlol, Epoch [13/15] loss is:1.7173\n",
      "Predicted string: ohlol, Epoch [14/15] loss is:1.7215\n",
      "Predicted string: ohlol, Epoch [15/15] loss is:1.7244\n"
     ]
    }
   ],
   "source": [
    "#训练过程 15个epoch\n",
    "for epoch in range(15):\n",
    "    loss=0\n",
    "    optimizer.zero_grad()\n",
    "    hidden=model1.init_hidden()\n",
    "    print('Predicted string: ',end='')\n",
    "    for input,label in zip(inputs,labels):\n",
    "        hidden=model1(input,hidden)\n",
    "        loss+=criterion(hidden,label)\n",
    "        predict=torch.max(hidden,dim=1).indices.item()\n",
    "        print(idx2char[predict],end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss is:%.4f'%(epoch+1,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "10e84934-6aa7-43da-ab69-2b4f546d89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用RNN实现一下\n",
    "class Net2(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,batch_size,num_layers):\n",
    "        super(Net2,self).__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.batch_size=batch_size\n",
    "        self.num_layers=num_layers\n",
    "        self.rnn=torch.nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "    def forward(self,inputs):\n",
    "        hidden=torch.zeros(self.num_layers,self.batch_size,self.hidden_size)\n",
    "        out,_=self.rnn(inputs,hidden)\n",
    "        out=out.view(-1,self.hidden_size)\n",
    "        return out\n",
    "model2=Net2(input_size,hidden_size,batch_size,num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0e487681-da84-4790-9aca-733db6ba1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失和优化\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model2.parameters(),lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05c98856-68d5-4639-b1a4-7ededb233dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:eeeee,epoch [1/15] loss=1.8657\n",
      "Predicted string:ooloe,epoch [2/15] loss=1.1752\n",
      "Predicted string:ohool,epoch [3/15] loss=0.8497\n",
      "Predicted string:ohool,epoch [4/15] loss=0.6763\n",
      "Predicted string:ohool,epoch [5/15] loss=0.5633\n",
      "Predicted string:ohool,epoch [6/15] loss=0.5096\n",
      "Predicted string:ohool,epoch [7/15] loss=0.4754\n",
      "Predicted string:ohool,epoch [8/15] loss=0.4598\n",
      "Predicted string:ohool,epoch [9/15] loss=0.4522\n",
      "Predicted string:ohool,epoch [10/15] loss=0.4475\n",
      "Predicted string:ohool,epoch [11/15] loss=0.4444\n",
      "Predicted string:ohool,epoch [12/15] loss=0.4423\n",
      "Predicted string:ohool,epoch [13/15] loss=0.4408\n",
      "Predicted string:ohool,epoch [14/15] loss=0.4397\n",
      "Predicted string:ohool,epoch [15/15] loss=0.4389\n"
     ]
    }
   ],
   "source": [
    "labels=torch.LongTensor(y_data)\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Predicted string:\",end='')\n",
    "    out=model2(inputs)\n",
    "    loss=criterion(out,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    out=torch.max(out,dim=1).indices\n",
    "    out=out.data.numpy()\n",
    "    print(\"\".join([idx2char[x] for x in out]),end='')\n",
    "    print(',epoch [%d/15] loss=%.4f'%(epoch+1,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2e02be-00f8-4b10-8f0d-8ef71a5feb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#词嵌入embedding算法\n",
    "#embedding层输入必需是LongTensor\n",
    "num_classes=4\n",
    "embedding_size=10\n",
    "input_size=4\n",
    "hidden_size=8\n",
    "seq_len=5\n",
    "num_layers=2\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79badd33-aa31-437b-8fbe-42090f7b2779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "idx2char=['e','h','l','o']\n",
    "x_data=[[1,0,2,2,3]] #embeddind输入的尺寸是（batch_size,seqlen）输出尺寸是(batch_size,seq_len,embedding_size)\n",
    "y_data=[3,1,2,3,2] \n",
    "input=torch.LongTensor(x_data)\n",
    "labels=torch.LongTensor(y_data)\n",
    "print(input.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af349675-3a59-403e-866a-2441b491f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "#定义模型\n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self,embedding_size,batch_size,input_size,hidden_size,num_layers,seq_len,num_classes):\n",
    "        super(Net3,self).__init__()\n",
    "        self.embeddingg_num=embedding_size\n",
    "        self.batch_size=batch_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.input_size=input_size\n",
    "        self.seq_len=seq_len\n",
    "        self.emb=torch.nn.Embedding(input_size,embedding_size)\n",
    "        self.rnn=torch.nn.RNN(input_size=embedding_size,hidden_size=hidden_size,num_layers=num_layers,batch_first=True)\n",
    "        self.fc=torch.nn.Linear(batch_size*hidden_size,num_classes)\n",
    "    def forward(self,x):\n",
    "        x=self.emb(x) #输入尺寸(batch_size,seq_len)输出尺寸(batch_size，seq_len,embedding_num)\n",
    "        x,_=self.rnn(x) #输出是\n",
    "        x=x.view(self.seq_len,-1)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "model3=Net3(embedding_num,batch_size,input_size,hidden_size,num_layers,seq_len,num_classes)\n",
    "output=model3(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d85a41-26a6-4255-8069-b0cb3661e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义交叉熵损失和优化器\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model3.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fef48c2-bd65-4fe6-85ef-7e2c495cbbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:eohoh,epoch [1/15] loss=1.4044\n",
      "Predicted string:ohlll,epoch [2/15] loss=1.0494\n",
      "Predicted string:ohlol,epoch [3/15] loss=0.5459\n",
      "Predicted string:ohlol,epoch [4/15] loss=0.3367\n",
      "Predicted string:ohlol,epoch [5/15] loss=0.1811\n",
      "Predicted string:ohlol,epoch [6/15] loss=0.1029\n",
      "Predicted string:ohlol,epoch [7/15] loss=0.0581\n",
      "Predicted string:ohlol,epoch [8/15] loss=0.0342\n",
      "Predicted string:ohlol,epoch [9/15] loss=0.0210\n",
      "Predicted string:ohlol,epoch [10/15] loss=0.0134\n",
      "Predicted string:ohlol,epoch [11/15] loss=0.0088\n",
      "Predicted string:ohlol,epoch [12/15] loss=0.0060\n",
      "Predicted string:ohlol,epoch [13/15] loss=0.0043\n",
      "Predicted string:ohlol,epoch [14/15] loss=0.0032\n",
      "Predicted string:ohlol,epoch [15/15] loss=0.0025\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Predicted string:\",end='')\n",
    "    out=model3(input)\n",
    "    loss=criterion(out,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    out=torch.max(out,dim=1).indices\n",
    "    out=out.data.numpy()\n",
    "    print(\"\".join([idx2char[x] for x in out]),end='')\n",
    "    print(',epoch [%d/15] loss=%.4f'%(epoch+1,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b08c8-27bf-4bfc-adef-f8c0f5684ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
