{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadd0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d72ee",
   "metadata": {},
   "source": [
    "# 灵活的模型构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2c9140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1167, -0.0221, -0.1987,  0.1602, -0.0675,  0.0579,  0.2181, -0.2926,\n",
       "          0.1254, -0.0453],\n",
       "        [ 0.0779,  0.0134, -0.0963,  0.1607,  0.0789,  0.0336,  0.2814, -0.2386,\n",
       "          0.0793, -0.1339]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10)) #Sequential是nn.Module的子类\n",
    "X=torch.rand(2,20) #均匀分布\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035fb8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0434, -0.2509, -0.0083,  0.0282,  0.2099, -0.0040, -0.0674, -0.0427,\n",
       "          0.0225,  0.1119],\n",
       "        [ 0.1472, -0.2190,  0.0708,  0.0665,  0.1904,  0.0088,  0.0466, -0.0129,\n",
       "          0.0568, -0.1035]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义快\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(20,256)\n",
    "        self.out=nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.linear(X)))\n",
    "model=MLP()\n",
    "X=torch.rand(2,20)\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efe7bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0128e-03, -1.2707e-01,  1.2986e-01,  1.8668e-02, -4.2986e-05,\n",
       "         -6.2636e-02, -4.2398e-01,  1.0492e-01, -1.2150e-01,  2.0344e-01],\n",
       "        [ 1.1496e-01,  9.6769e-03,  1.2532e-01, -6.4050e-02,  3.8905e-02,\n",
       "         -2.1810e-02, -2.0412e-01,  2.2321e-01, -1.0144e-01, -6.1645e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实现nn.Sequential类\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block]=block\n",
    "            \n",
    "    def forward(self,X):\n",
    "        for block in self._modules.values():\n",
    "            X=block(X)\n",
    "        return X\n",
    "net=MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "X=torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d022e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2392, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weights=torch.rand((20,20),requires_grad=False)\n",
    "        self.linear=nn.Linear(20,20)\n",
    "    def forward(self,X):\n",
    "        X=self.linear(X)\n",
    "        X=F.relu(torch.mm(X,self.rand_weights)+1)\n",
    "        X=self.linear(X)\n",
    "        while X.abs().sum()>1:\n",
    "            X/=2\n",
    "        return X.sum()\n",
    "net=FixHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4056683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#也可以嵌套nn.Sequential和nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5e3cd",
   "metadata": {},
   "source": [
    "# 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a32d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2574],\n",
       "        [0.1737]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X=torch.rand(2,4)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89661d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.2118, -0.1311, -0.0670,  0.2268,  0.2373, -0.0673,  0.2884,  0.1917]])), ('bias', tensor([-0.1021]))])\n"
     ]
    }
   ],
   "source": [
    "# 参数访问\n",
    "print(net[2].state_dict()) #拿出第二层的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb78e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1021], requires_grad=True)\n",
      "tensor([-0.1021])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e5de01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad==None #没有做反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07dffaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "# 把网络中所有的参数拿出来\n",
    "print(*[(name,param.shape) for name,param in net[0].named_parameters()])#其中的*是把列表中的元素提取出来再打印\n",
    "print(*[(name,param.shape) for name,param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afda963b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[ 0.4930,  0.4190, -0.2970, -0.1321],\n",
       "                      [-0.3947,  0.3195, -0.2461,  0.2102],\n",
       "                      [-0.1995,  0.3835,  0.2205, -0.1285],\n",
       "                      [ 0.0518,  0.3629,  0.3224, -0.4075],\n",
       "                      [-0.4789, -0.3011,  0.4604, -0.3170],\n",
       "                      [ 0.0703,  0.1764,  0.0018,  0.0486],\n",
       "                      [-0.4274,  0.4576,  0.2454,  0.2247],\n",
       "                      [-0.2330, -0.0544,  0.3983,  0.4250]])),\n",
       "             ('0.bias',\n",
       "              tensor([ 0.1586, -0.1077, -0.1490, -0.2461,  0.1355, -0.4909, -0.0618,  0.4093])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.2118, -0.1311, -0.0670,  0.2268,  0.2373, -0.0673,  0.2884,  0.1917]])),\n",
       "             ('2.bias', tensor([-0.1021]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d229b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1021])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca415754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "OrderedDict([('0.block0.0.weight', tensor([[ 0.3090,  0.0190,  0.4618,  0.0950],\n",
      "        [ 0.3028, -0.0201, -0.4716,  0.1038],\n",
      "        [ 0.0097,  0.4959,  0.4484,  0.3578],\n",
      "        [ 0.3806,  0.1563, -0.3681,  0.0122],\n",
      "        [ 0.2037, -0.2524, -0.2082, -0.4517],\n",
      "        [ 0.0531,  0.1896, -0.0580, -0.2536],\n",
      "        [-0.4614, -0.4861, -0.0977, -0.2345],\n",
      "        [-0.3633, -0.0857, -0.2272, -0.4105]])), ('0.block0.0.bias', tensor([ 0.2271,  0.4939,  0.3934,  0.0097, -0.4989,  0.3574, -0.0382,  0.0476])), ('0.block0.2.weight', tensor([[-0.1705,  0.1351,  0.2767, -0.1514,  0.0599,  0.2102,  0.3077,  0.2278],\n",
      "        [ 0.0667,  0.0306,  0.2568,  0.3174,  0.3094,  0.2667,  0.1710, -0.3425],\n",
      "        [-0.3319, -0.2048,  0.1924, -0.2582, -0.2733, -0.0126, -0.2702,  0.2781],\n",
      "        [ 0.2557, -0.2611,  0.1488, -0.2769, -0.1737,  0.0821, -0.0699, -0.0270]])), ('0.block0.2.bias', tensor([ 0.1275,  0.1347, -0.0417, -0.1113])), ('0.block1.0.weight', tensor([[-0.2934, -0.1464,  0.1921, -0.0705],\n",
      "        [-0.4013, -0.1964, -0.4519,  0.2880],\n",
      "        [-0.2732,  0.0954, -0.3906,  0.4052],\n",
      "        [-0.1135,  0.1004,  0.3419,  0.4592],\n",
      "        [ 0.0543,  0.2256,  0.2647, -0.1246],\n",
      "        [-0.2397,  0.1940,  0.4223, -0.2566],\n",
      "        [-0.4344, -0.3647,  0.2878,  0.3062],\n",
      "        [-0.2062,  0.0078, -0.0344, -0.1327]])), ('0.block1.0.bias', tensor([-0.2448,  0.3198,  0.4848,  0.2932, -0.0515,  0.4241, -0.0111,  0.2780])), ('0.block1.2.weight', tensor([[ 0.3448, -0.0479,  0.1703,  0.1206,  0.0681,  0.1642,  0.2737,  0.2246],\n",
      "        [-0.2054, -0.1518, -0.3442,  0.0889, -0.2388, -0.2227, -0.1540, -0.0849],\n",
      "        [-0.0288, -0.3301, -0.1028,  0.0025, -0.3047,  0.2225, -0.0434, -0.2925],\n",
      "        [ 0.1295, -0.2156,  0.1403,  0.3325,  0.1067,  0.0636,  0.0856, -0.2430]])), ('0.block1.2.bias', tensor([-0.3049, -0.0282, -0.1660, -0.3492])), ('0.block2.0.weight', tensor([[ 0.0224,  0.1679,  0.4501,  0.4183],\n",
      "        [-0.1460, -0.3874, -0.1922, -0.1035],\n",
      "        [ 0.0705,  0.1908, -0.4763,  0.4759],\n",
      "        [-0.0337, -0.0287,  0.2569,  0.1108],\n",
      "        [ 0.0222,  0.4777,  0.2122, -0.2543],\n",
      "        [-0.4237, -0.2669,  0.4774,  0.2225],\n",
      "        [-0.3883, -0.1643,  0.3271, -0.3640],\n",
      "        [ 0.1791, -0.3053, -0.3882, -0.1271]])), ('0.block2.0.bias', tensor([-0.3578,  0.0489,  0.1936, -0.3211,  0.0950,  0.4730, -0.0247,  0.4022])), ('0.block2.2.weight', tensor([[-0.2068,  0.2377,  0.0238,  0.0449, -0.2870, -0.2763, -0.2966,  0.3447],\n",
      "        [-0.2591,  0.3419, -0.1091,  0.0047, -0.2228, -0.0223,  0.0639,  0.1625],\n",
      "        [-0.0615, -0.2583, -0.3199, -0.1284, -0.3369,  0.2601, -0.1097,  0.1346],\n",
      "        [-0.2518, -0.2594, -0.3377,  0.0028, -0.2378,  0.0582,  0.0848,  0.3171]])), ('0.block2.2.bias', tensor([-0.2352,  0.0632,  0.2450, -0.0373])), ('0.block3.0.weight', tensor([[ 0.3926,  0.3972,  0.4488, -0.3411],\n",
      "        [ 0.2887,  0.1636, -0.3224, -0.1538],\n",
      "        [-0.1409,  0.4549, -0.3151, -0.1041],\n",
      "        [-0.3408, -0.4558, -0.3869, -0.3661],\n",
      "        [ 0.0412, -0.0505, -0.1500,  0.3712],\n",
      "        [-0.4487, -0.2454, -0.4770,  0.1951],\n",
      "        [ 0.4124, -0.3776, -0.2438, -0.1785],\n",
      "        [ 0.2811, -0.0186,  0.4145,  0.2350]])), ('0.block3.0.bias', tensor([-0.3480, -0.2708,  0.1390, -0.0924, -0.1436, -0.4166,  0.3271,  0.0836])), ('0.block3.2.weight', tensor([[ 0.0656,  0.1583, -0.0374,  0.2773,  0.1145, -0.1971,  0.0856, -0.1647],\n",
      "        [ 0.1062, -0.2424,  0.0295, -0.2452, -0.0038,  0.2648,  0.1940,  0.0060],\n",
      "        [ 0.2018, -0.0673,  0.0867,  0.1123,  0.0534,  0.1122,  0.2197, -0.0900],\n",
      "        [ 0.1102, -0.2663, -0.0841, -0.0003, -0.0593, -0.3019, -0.2736, -0.2065]])), ('0.block3.2.bias', tensor([ 0.1498, -0.1436, -0.0607,  0.2321])), ('1.weight', tensor([[0.2292, 0.1403, 0.4359, 0.3511]])), ('1.bias', tensor([0.0210]))])\n"
     ]
    }
   ],
   "source": [
    "# 从嵌套块中收集参数\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,4),nn.ReLU())\n",
    "def block2():\n",
    "    net=nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block{i}',block1())\n",
    "    return net\n",
    "rgnet=nn.Sequential(block2(),nn.Linear(4,1))\n",
    "print(rgnet)\n",
    "print(rgnet.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59c498e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.]),\n",
       " tensor([[ 0.0027, -0.0079, -0.0006, -0.0084,  0.0074, -0.0073,  0.0029,  0.0055]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#内置初始化参数\n",
    "def init_weight(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,mean=0,std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_weight)\n",
    "net[2].bias.data,net[2].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f83ada3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc02cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1420, -0.2103,  0.1461,  0.5881],\n",
      "        [-0.5539,  0.0350,  0.6983,  0.6135],\n",
      "        [-0.0249,  0.0087, -0.6010, -0.4886],\n",
      "        [ 0.0863, -0.6371, -0.5282,  0.3626],\n",
      "        [-0.1899,  0.2108, -0.2150,  0.5823],\n",
      "        [ 0.4387, -0.2708,  0.6383,  0.1103],\n",
      "        [-0.4769, -0.0934,  0.5443, -0.5920],\n",
      "        [ 0.6163,  0.1458,  0.5387, -0.2086]])\n"
     ]
    }
   ],
   "source": [
    "#用xavier初始化\n",
    "def xavier(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "net[0].apply(xavier)\n",
    "print(net[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "826141e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义初始化\n",
    "#更简单暴力的方法，把网络中的权重拿出来直接做替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "507a3396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#共享权重\n",
    "shared=nn.Linear(8,8)\n",
    "net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.Linear(8,16),nn.ReLU(),nn.Linear(16,8),nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))\n",
    "net[2].weight.data==net[7].weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e9080",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "571601f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        return X-X.mean()\n",
    "layer=CenteredLayer()\n",
    "layer(torch.tensor([1.0,2,3,4,5]))\n",
    "layer(torch.FloatTensor([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cc377ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0365],\n",
       "        [0.1579],\n",
       "        [0.0542],\n",
       "        [0.0647]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Sequential(nn.Linear(8,128),CenteredLayer(),nn.Linear(128,1))\n",
    "X=torch.rand(4,8)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a51c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0266, 0.0000, 0.0000],\n",
       "        [2.0189, 1.7062, 0.3353]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#带参数的类\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,in_units,out_units):\n",
    "        super().__init__()\n",
    "        self.weights=nn.Parameter(torch.randn(in_units,out_units))\n",
    "        self.bias=nn.Parameter(torch.zeros(out_units))\n",
    "    def forward(self,X):\n",
    "        y=torch.mm(X,self.weights.data)+self.bias.data\n",
    "        return F.relu(y)\n",
    "dense=MyLinear(5,3)\n",
    "dense.weights\n",
    "dense(torch.rand(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c2c4e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2045],\n",
       "        [-0.0153],\n",
       "        [ 0.0097],\n",
       "        [ 0.2535],\n",
       "        [-0.0016]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用自己写的层来构造模型\n",
    "net=nn.Sequential(MyLinear(4,16),nn.Linear(16,1))\n",
    "net(torch.rand(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4169fe2",
   "metadata": {},
   "source": [
    "# 保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cea1ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(6)\n",
    "torch.save(x,'x_file')\n",
    "x1=torch.load('x_file')\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f28d8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5]), tensor([0., 0., 0.]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存一个张量列表\n",
    "y=torch.zeros(3)\n",
    "torch.save([x,y],'xy_file')\n",
    "x1,y1=torch.load('xy_file')\n",
    "(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4c18e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3, 4, 5]), 'y': tensor([0., 0., 0.])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存字典\n",
    "dict={'x':x,'y':y}\n",
    "torch.save(dict,'mydict')\n",
    "mydict=torch.load('mydict')\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c18a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载和保存模型参数\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1=nn.Linear(20,256)\n",
    "        self.linear2=nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        return self.linear2(F.relu(self.linear1(X)))\n",
    "net=MLP()\n",
    "X=torch.rand(2,20)\n",
    "Y=net(X)\n",
    "torch.save(net.state_dict(),'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d71a84bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone=MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "Y_clone=clone(X)\n",
    "Y_clone==Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c33cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
